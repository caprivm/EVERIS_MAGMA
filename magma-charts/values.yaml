# Copyright 2020 The Magma Authors.

# This source code is licensed under the BSD-style license found in the
# LICENSE file in the root directory of this source tree.

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

## Global values for NMS sub-chart
nms:
  enabled: true
  secret:
      certs: orc8r-secrets-certs
  
  magmalte:
    create: true
    env:
      api_host: orc8r-nginx-proxy.magma.svc.cluster.local:443
      host: 0.0.0.0
      port: 8081
      mapbox_access_token: ""
      mysql_host: mysql3-mariadb.magma.svc.cluster.local
      mysql_db: magma
      mysql_user: root
      mysql_pass: bK73abE9Jn
      mysql_dialect: mariadb
      grafana_address: orc8r-user-grafana:3000

    labels: {}

    image:
      repository: docker.io/caprivm/magmalte
      tag: 1.3.2
      pullPolicy: Always
    
    deployment:
      spec:
        operator_cert_name: admin_operator.pem
        operator_key_name: admin_operator.key.pem

    service:
      type: ClusterIP
      http:
        port: 8081
        targetport: 8081
        nodePort: ""
    
    replicas: 1
  
    # Resource limits & requests
    resources: {}
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi
  
    # Define which Nodes the Pods are scheduled on.
    # ref: https://kubernetes.io/docs/user-guide/node-selection/
    nodeSelector: {}
  
    # Tolerations for use with node taints
    # ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
    tolerations: []
  
    # Assign proxy to run on specific nodes
    # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
    affinity: {}
  
  ## Nginx-Proxy
  nginx:
    create: true
    labels: {}

    image:
      repository: nginx
      tag: latest
      pullPolicy: Always
  
    service:
      type: LoadBalancer
      annotations: {}
      https:
        port: 443
        targetport: 443
        nodePort: ""

    deployment:
      spec:
        ssl_cert_name: nms_nginx.pem
        ssl_cert_key_name: nms_nginx.key.pem

    replicas: 1
  
    # Resource limits & requests
    resources: {}
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi
  
    # Define which Nodes the Pods are scheduled on.
    # ref: https://kubernetes.io/docs/user-guide/node-selection/
    nodeSelector: {}
  
    # Tolerations for use with node taints
    # ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
    tolerations: []
  
    # Assign proxy to run on specific nodes
    # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
    affinity: {}

##### End of NMS Chart

# Reference to one or more secrets to be used when pulling images
# ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
imagePullSecrets: []
# - name: orc8r-secrets-registry

# Metrics sub-chart configuration.
metrics:
  enabled: false
  metrics:
    volumes:
      prometheusData:
        volumeSpec:
          hostPath:
            path: /prometheusData
            type: DirectoryOrCreate
        # persistentVolumeClaim:
          # claimName: promcfg
      prometheusConfig:
        volumeSpec:
          hostPath:
            path: /configs/prometheus
            type: DirectoryOrCreate
        # persistentVolumeClaim:
          # claimName: promdata

  grafana:
    create: false
   
  userGrafana:
    create: true 
    volumes:
      # Default volume configurations for grafana data.
      dashboards:
        hostPath:
          path: /grafanaData/dashboards
          type: DirectoryOrCreate
              #volumeSpec:
                # persistentVolumeClaim:
                #claimName: grafanadashboards
      datasources:
        hostPath:
          path: /grafanaData/datasources
          type: DirectoryOrCreate
              # volumeSpec:
                #persistentVolumeClaim:
                #claimName: grafanadatasources
      dashboardproviders:
        hostPath:
          path: /grafanaData/dashboardproviders
          type: DirectoryOrCreate
              #volumeSpec:
                #persistentVolumeClaim:
                #claimName: grafanaproviders
      grafanaData:
        hostPath:
          path: /grafanaData/grafanaData
          type: DirectoryOrCreate
              #volumeSpec:
              #persistentVolumeClaim:
              #claimName: grafanadata

  prometheus:
    create: true

  prometheusCache:
    create: true
    image:
      repository: docker.io/facebookincubator/prometheus-edge-hub
      tag: "1.0.0" # Double quote to cast to string
      pullPolicy: IfNotPresent
    limit: 500000
    service:
      type: LoadBalancer

  alertmanager:
    create: true

  alertmanagerConfigurer:
    create: true
    image:
      repository: docker.io/facebookincubator/alertmanager-configurer
      tag: 1.0.0
      pullPolicy: IfNotPresent

  prometheusConfigurer:
    create: true
    image:
      repository: docker.io/facebookincubator/prometheus-configurer
      tag: 1.0.0
      pullPolicy: IfNotPresent

#### Beginning of Secrets Sub-Chart

# Secrets sub-chart configuration.
secrets:
  create: true

##### End of Secrets Sub-Chart  
#
# Define which secrets should be mounted by pods.
# secret:
#  certs: orc8r-secrets-certs
#  configs:
#    orc8r: orc8r-secrets-configs-orc8r
#  envdir: orc8r-secrets-envdir

nginx:
  create: true
  
  # Configure pod disruption budgets for nginx
  # ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/#specifying-a-poddisruptionbudget
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
    maxUnavailable: ""

  # Service configuration.
  service:
    enabled: true
    legacyEnabled: true
    name: bootstrapper-orc8r-nginx
    annotations: {}
    extraAnnotations:
      bootstrapLagacy: {}
      clientcertLegacy: {}
      proxy: {}
    labels: {}
    type: LoadBalancer
    port:
      clientcert:
        port: 8443
        targetPort: 8443
        nodePort: ""
      open:
        port: 8444
        targetPort: 8444
        nodePort: ""
      api:
        port: 443
        targetPort: 9443
        nodePort: ""
      health:
        port: 80
        targetPort: 80
        nodePort: ""
    loadBalancerIP: ""
    loadBalancerSourceRanges: []

  # nginx image
  image:
    repository: docker.io/caprivm/nginx
    tag: 1.3.2
    pullPolicy: IfNotPresent

  # Settings affecting nginx application
  spec:
    # magma controller domain name
    hostname: "orc8r" # "controller.magma.test"
    # when nginx sees a variable in a server_name it needs a resolver
    # by default we'll use kube-dns
    resolver: "coredns.kube-system.svc.cluster.local valid=10s"

  # Number of nginx replicas desired
  replicas: 1

  # Resource limits & requests
  resources: {}
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

  # Define which Nodes the Pods are scheduled on.
  # ref: https://kubernetes.io/docs/user-guide/node-selection/
  nodeSelector: {}

  # Tolerations for use with node taints
  # ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []

  # Assign nginx to run on specific nodes
  # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
  affinity: {}

controller:
  # Define which secrets should be mounted by pods.
  secret:
    certs: orc8r-secrets-certs
    configs:
      orc8r: orc8r-secrets-configs-orc8r
    envdir: orc8r-secrets-envdir
  
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
    maxUnavailable: ""

  # Service configuration.
  service:
    annotations: {}
    labels: {}
    type: ClusterIP
    port: 8080
    targetPort: 8080
    # port range exposed by controller
    portStart: 9079
    portEnd: 9108

  # Controller image
  image:
    repository: docker.io/caprivm/controller
    tag: 1.3.2
    pullPolicy: IfNotPresent
  
  spec:
    # Postgres/mysql configuration
    database:
      driver: postgres  # mysql/postgres
      sql_dialect: psql # maria/psql
      db: magma         # DB Name
      protocol: tcp
      host: postgresql.magma.svc.cluster.local
      port: 5432
      user: postgres
      pass: postgres
  
  migration:
    new_handlers: 0
    new_mconfigs: 0
    mconfig_whitelist: ""

  podAnnotations: {}

  # Number of controller replicas desired
  replicas: 1

  # Resource limits & requests
  resources: {}
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

  # Define which Nodes the Pods are scheduled on.
  # ref: https://kubernetes.io/docs/user-guide/node-selection/
  nodeSelector: {}

  # Tolerations for use with node taints
  # ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []

  # Assign proxy to run on specific nodes
  # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
  affinity: {}

# Set True to create a CloudWatch agent to monitor metrics
cloudwatch:
  create: false

# logging sub-chart configuration.
logging:
  enabled: true
